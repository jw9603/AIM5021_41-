{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (3.7)\n","Requirement already satisfied: tqdm in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n","Requirement already satisfied: regex>=2021.8.3 in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n","Requirement already satisfied: joblib in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n","Requirement already satisfied: click in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4395,"status":"ok","timestamp":1668581120611,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"bfdT8xxdFDnI","outputId":"aa381f1c-e1f5-431c-f199-b27e2e2e8946"},"outputs":[],"source":["import nltk\n","nltk.download('all')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3464,"status":"ok","timestamp":1668581130859,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"0tYkOqvTFMAk","outputId":"7027c580-5751-4cea-9c3c-00ce51348214"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gensim in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n","Requirement already satisfied: scipy>=0.18.1 in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.0 in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.21.5)\n","Requirement already satisfied: smart-open>=1.8.1 in /Users/jeongjiwon/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.1.0)\n"]}],"source":["!pip install gensim"]},{"cell_type":"markdown","metadata":{"id":"5uwn9_R-GJ8k"},"source":["### 1. 영어 word2vec 만들기"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":517,"status":"ok","timestamp":1668581124836,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"8HWJu9qOGJSx"},"outputs":[],"source":["import re\n","import urllib.request\n","import zipfile\n","from lxml import etree\n","from nltk.tokenize import word_tokenize, sent_tokenize"]},{"cell_type":"markdown","metadata":{"id":"SOlqxF2NGUDf"},"source":["#### 1) 훈련 데이터 이해하기"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1112,"status":"ok","timestamp":1668580175373,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"HQXGadeWGTQh","outputId":"ae14745a-5b47-4158-b2a6-3d65afaf299e"},"outputs":[{"data":{"text/plain":["('ted_en-20160408.xml', <http.client.HTTPMessage at 0x1559bbca0>)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# 데이터 다운로드\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"]},{"cell_type":"markdown","metadata":{"id":"4SG6vaz7GZAK"},"source":["\n","훈련 데이터 파일은 xml 문법으로 작성되어 있어 자연어를 얻기 위해서는 전처리가 필요합니다. 얻고자 하는 실질적 데이터는 영어문장으로만 구성된 내용을 담고 있는 <content>와 </content> 사이의 내용입니다. 전처리 작업을 통해 xml 문법들은 제거하고, 해당 데이터만 가져와야 합니다. 뿐만 아니라, <content>와 </content> 사이의 내용 중에는 (Laughter)나 (Applause)와 같은 배경음을 나타내는 단어도 등장하는데 이 또한 제거해야 합니다."]},{"cell_type":"markdown","metadata":{"id":"8aYbwpVjGhvE"},"source":["#### 2) 훈련 데이터 전처리 하기"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":439786,"status":"error","timestamp":1668580616316,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"POeQF-DUGeAk","outputId":"7d0ea581-ec28-4bd8-96d8-83e890865aa6"},"outputs":[],"source":["targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","sent_text = sent_tokenize(content_text)\n","\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","result = [word_tokenize(sentence) for sentence in normalized_text]"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1668580616317,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"aY7vjZM5GmTZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["총 샘플의 개수 : 273380\n"]}],"source":["print('총 샘플의 개수 : {}'.format(len(result)))"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1668580616317,"user":{"displayName":"정지원","userId":"16823124283758121408"},"user_tz":-540},"id":"gnwAja6jGojE"},"outputs":[{"name":"stdout","output_type":"stream","text":["['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n","['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n","['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"]}],"source":["# 샘플 3개만 출력\n","for line in result[:3]:\n","    print(line)"]},{"cell_type":"markdown","metadata":{"id":"uzrs4blaGpyM"},"source":["#### 3) Word2Vec 훈련시키기"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"iXZbRdT5FQzu"},"outputs":[],"source":["from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","\n","model = Word2Vec(sentences=result, window=5, min_count=5, workers=4, sg=1)   # Skip-gram\n","model1 = Word2Vec(sentences=result, window=5, min_count=5, workers=4, sg=0)  # CBOW "]},{"cell_type":"markdown","metadata":{"id":"ugUQueopFuNL"},"source":["- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n","- window = 컨텍스트 윈도우 크기\n","- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n","- workers = 학습을 위한 프로세스 수\n","- sg = 0은 CBOW, 1은 Skip-gram."]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('woman', 0.7396081686019897), ('guy', 0.7281558513641357), ('boy', 0.7062798738479614), ('rabbi', 0.6883109211921692), ('michelangelo', 0.6649431586265564), ('soldier', 0.6605366468429565), ('pianist', 0.6581396460533142), ('psychiatrist', 0.6554989218711853), ('testament', 0.6552859544754028), ('person', 0.6517705321311951)]\n","-----------------------------------------------------------------------\n","\n","[('woman', 0.8330977559089661), ('guy', 0.8008432388305664), ('lady', 0.7870305180549622), ('boy', 0.7807929515838623), ('girl', 0.7462363243103027), ('soldier', 0.7294784188270569), ('gentleman', 0.7160805463790894), ('kid', 0.7051184177398682), ('poet', 0.6941379308700562), ('surgeon', 0.680122971534729)]\n"]}],"source":["model_result = model.wv.most_similar(\"man\")    # skip-gram\n","print(model_result)\n","print('-----------------------------------------------------------------------\\n')\n","model1_result = model1.wv.most_similar(\"man\")  # CBOW\n","print(model1_result)"]},{"cell_type":"markdown","metadata":{},"source":["#### 4) Word2Vec 모델 저장하고 로드하기"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n","loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드\n","\n","model1.wv.save_word2vec_format('eng_w2v') # 모델 저장\n","loaded_model1 = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('woman', 0.7396081686019897), ('guy', 0.7281558513641357), ('boy', 0.7062798738479614), ('rabbi', 0.6883109211921692), ('michelangelo', 0.6649431586265564), ('soldier', 0.6605366468429565), ('pianist', 0.6581396460533142), ('psychiatrist', 0.6554989218711853), ('testament', 0.6552859544754028), ('person', 0.6517705321311951)]\n","-----------------------------------------------\n","\n","[('woman', 0.8330977559089661), ('guy', 0.8008432388305664), ('lady', 0.7870305180549622), ('boy', 0.7807929515838623), ('girl', 0.7462363243103027), ('soldier', 0.7294784188270569), ('gentleman', 0.7160805463790894), ('kid', 0.7051184177398682), ('poet', 0.6941379308700562), ('surgeon', 0.680122971534729)]\n"]}],"source":["# 로드한 모델에 대해서 다시 man과 유사한 단어를 출력\n","model_result = loaded_model.most_similar(\"man\")\n","print(model_result)\n","print('-----------------------------------------------\\n')\n","model1_result = loaded_model1.most_similar(\"man\")\n","print(model1_result)"]},{"cell_type":"markdown","metadata":{"id":"XaW7xsI-JuMA"},"source":["### Use Pre-trained Google Word2vec model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gdFE4G5vFxBQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('queen', 0.7118192911148071)]\n"]}],"source":["from gensim.models import KeyedVectors\n","filename = 'GoogleNews-vectors-negative300.bin'\n","# load the google word2vec model\n","model = KeyedVectors.load_word2vec_format(filename, binary=True)\n","# calculate: (king - man) + woman = ?\n","result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["### Doc2vec Train using Gensim"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus :  [TaggedDocument(words=['This', 'is', 'the', 'first', 'document', '.'], tags=['d0']), TaggedDocument(words=['This', 'document', 'is', 'the', 'second', 'document', '.'], tags=['d1']), TaggedDocument(words=['And', 'this', 'is', 'the', 'third', 'one', '.'], tags=['d2']), TaggedDocument(words=['Is', 'this', 'the', 'first', 'document', '?'], tags=['d3'])]\n","----------------------------------------------------------------\n","\n","<gensim.models.keyedvectors.KeyedVectors object at 0x157c82700>\n","[-0.10476875 -0.11964148 -0.19767322  0.17072192  0.07122663]\n","[ 0.00511192 -0.19766597 -0.10348055 -0.1945817   0.04013548]\n","[ 0.05658225  0.09294482 -0.08611333 -0.06295341 -0.06163875]\n","[-0.17477198  0.04350599  0.18467224 -0.19060297 -0.06943313]\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/2580391979.py:12: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  print(model.docvecs)\n","/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/2580391979.py:13: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  print(model.docvecs[0])\n","/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/2580391979.py:14: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  print(model.docvecs[1])\n","/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/2580391979.py:15: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  print(model.docvecs[2])\n","/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/2580391979.py:16: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  print(model.docvecs[3])\n"]}],"source":["from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n","from nltk.tokenize import word_tokenize\n","corpus = [ 'This is the first document.',\n","'This document is the second document.',\n","'And this is the third one.',\n","'Is this the first document?' ]\n","corpus = [list(word_tokenize(doc)) for doc in corpus]\n","corpus = [ TaggedDocument(words, ['d{}'.format(idx)]) for idx, words in enumerate(corpus) ]\n","print(\"corpus : \",corpus)\n","model = Doc2Vec(corpus, vector_size=5, min_count=0)\n","print('----------------------------------------------------------------\\n')\n","print(model.docvecs)\n","print(model.docvecs[0])\n","print(model.docvecs[1])\n","print(model.docvecs[2])\n","print(model.docvecs[3])\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.0, 0.14078726, -0.29381293, -0.5908979, 0.14078726, 1.0, 0.012296972, 0.0581112, -0.29381293, 0.012296972, 1.0, -0.10139175, -0.5908979, 0.0581112, -0.10139175, 1.0]\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/rn/7s4510t94j703wxxn5gjx2lc0000gn/T/ipykernel_15614/1854483201.py:11: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n","  cos_list.append(cos_sim(model.docvecs[i],model.docvecs[j]))\n"]}],"source":["import numpy as np\n","from numpy import dot\n","from numpy.linalg import norm\n","\n","def cos_sim(A, B):\n","  return dot(A, B)/(norm(A)*norm(B))\n","\n","cos_list = []\n","for i in range(4):\n","  for j in range(4):\n","    cos_list.append(cos_sim(model.docvecs[i],model.docvecs[j]))\n","print(cos_list)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNp7E7rkPZXqbNqpEiOZVhT","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"0ffc5a65df4473e5ec978d296e44db7a5ae5a6aeaf8451573edc3b07e9460cdb"}}},"nbformat":4,"nbformat_minor":0}
